{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T04:17:04.692674Z",
     "start_time": "2022-06-24T04:17:04.688912Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T04:17:28.093935Z",
     "start_time": "2022-06-24T04:17:27.820100Z"
    }
   },
   "outputs": [],
   "source": [
    "from ankisync2 import Apkg\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import itertools\n",
    "import math\n",
    "import sqlite3\n",
    "from contextlib import closing\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T04:17:06.072612Z",
     "start_time": "2022-06-24T04:17:06.064727Z"
    }
   },
   "outputs": [],
   "source": [
    "class Helpers(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_html_tags(markup):\n",
    "        soup = BeautifulSoup(markup, 'html.parser')\n",
    "        for br in soup.find_all('br'):\n",
    "            br.replace_with('\\n')\n",
    "        return soup.get_text()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_images(markup):\n",
    "        out = []\n",
    "        if markup:\n",
    "            soup = BeautifulSoup(markup, 'html.parser')\n",
    "            images = soup.findAll('img')\n",
    "            for image in images:\n",
    "                out.append(image['src'])\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_cloze(markup):\n",
    "        # txt = '<a href=\"blah\"> Hello {{c1::world}} once {{c2::again::hint}} lol </a>'\n",
    "        return re.sub('{{.*?::(.*?)(::.*?){0,}}}', '\\\\1', markup)\n",
    "\n",
    "    @staticmethod\n",
    "    def telescope_tags(taglist):\n",
    "        out = []\n",
    "        for tag in taglist:\n",
    "            splt = tag.lower().split('::')\n",
    "            for i in range(1, len(splt)):\n",
    "                out.append('::'.join(splt[0:i]))\n",
    "        return set(out)\n",
    "\n",
    "    @staticmethod\n",
    "    def jaccard_similarity(list1, list2):\n",
    "        s1 = set(list1)\n",
    "        s2 = set(list2)\n",
    "        try:\n",
    "            jaccard = float(len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "        except ZeroDivisionError:\n",
    "            jaccard = 0\n",
    "        return jaccard\n",
    "    \n",
    "    @staticmethod\n",
    "    def intersection_size(list1, list2):\n",
    "        s1 = set(list1)\n",
    "        s2 = set(list2)\n",
    "        return len(s1.intersection(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T04:17:08.084310Z",
     "start_time": "2022-06-24T04:17:08.051491Z"
    }
   },
   "outputs": [],
   "source": [
    "class SQL(object):\n",
    "    DELAY = 0.5  # Just for display purposes\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "\n",
    "    def init_sql(self):\n",
    "        print(f'Creating new storage db at {self.path}')\n",
    "        conn = sqlite3.connect(self.path)\n",
    "        cursor = conn.cursor()\n",
    "        for tbl in ['cards', 'tags', 'images',\n",
    "                    'note_image_sim', 'note_tag_sim', 'note_text_sim', 'note_overall_sim',\n",
    "                    'tag_sim', 'image_sim']:\n",
    "            cursor.execute(f'DROP TABLE IF EXISTS {tbl}')\n",
    "\n",
    "        cursor.execute('CREATE TABLE cards (card_id integer);')\n",
    "        cursor.execute('CREATE TABLE tags (tag string);')\n",
    "        cursor.execute('CREATE TABLE images (image string);')\n",
    "        cursor.execute('CREATE INDEX cards_idx ON cards (card_id);')\n",
    "        cursor.execute('CREATE INDEX tags_idx ON tags (tag);')\n",
    "        cursor.execute('CREATE INDEX images_idx ON images (image);')\n",
    "\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_image_sim\n",
    "                       (card_a integer, \n",
    "                       card_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (card_a) REFERENCES cards (card_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (card_b) REFERENCES cards (card_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute(\n",
    "            'CREATE INDEX note_image_sim_idx ON note_image_sim (card_a, card_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_tag_sim\n",
    "                       (card_a integer, \n",
    "                       card_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (card_a) REFERENCES cards (card_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (card_b) REFERENCES cards (card_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute(\n",
    "            'CREATE INDEX note_tag_sim_idx ON note_tag_sim (card_a, card_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_text_sim\n",
    "                       (card_a integer, \n",
    "                       card_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (card_a) REFERENCES cards (card_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (card_b) REFERENCES cards (card_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute(\n",
    "            'CREATE INDEX note_text_sim_idx ON note_text_sim (card_a, card_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_overall_sim\n",
    "                       (card_a integer, \n",
    "                       card_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (card_a) REFERENCES cards (card_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (card_b) REFERENCES cards (card_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute(\n",
    "            'CREATE INDEX note_overall_sim_idx ON note_overall_sim (card_a, card_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE tag_sim\n",
    "                       (tag_a string, \n",
    "                       tag_b string,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (tag_a) REFERENCES tags (tag) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (tag_b) REFERENCES tags (tag) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX tag_sim_idx ON tag_sim (tag_a, tag_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE image_sim\n",
    "                       (image_a string, \n",
    "                       image_b string,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (image_a) REFERENCES images (image) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (image_b) REFERENCES images (image) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute(\n",
    "            'CREATE INDEX image_sim_idx ON image_sim (image_a, image_b);')\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "    def execute(self, sql, params=()):\n",
    "        with closing(sqlite3.connect(self.path)) as conn:\n",
    "            with conn:\n",
    "                cur = conn.cursor()\n",
    "                try:\n",
    "                    sleep(self.DELAY)\n",
    "                    cur.execute(sql, params)\n",
    "                    res = cur.fetchall()\n",
    "                except sqlite3.ProgrammingError:\n",
    "                    print(f'SQL:\\n{sql}\\n{params}')\n",
    "\n",
    "                if res:\n",
    "                    df = pd.DataFrame(res)\n",
    "                    df.columns = [d[0] for d in cur.description]\n",
    "                else:\n",
    "                    df = pd.DataFrame({})\n",
    "        return df\n",
    "\n",
    "    def insert_vals(self, sql, param_list):\n",
    "        with closing(sqlite3.connect(self.path)) as conn:\n",
    "            with conn:\n",
    "                cur = conn.cursor()\n",
    "                try:\n",
    "                    sleep(self.DELAY)\n",
    "                    for params in tqdm(param_list, 'Serializing', position=0, leave=True):\n",
    "                        if isinstance(params, int) or isinstance(params, str):\n",
    "                            cur.execute(sql, (params,))\n",
    "                        else:\n",
    "                            cur.execute(sql, params)\n",
    "                    res = cur.fetchall()\n",
    "                except:\n",
    "                    print(f'SQL:\\n{sql}\\n{params}')\n",
    "                    res = None\n",
    "\n",
    "                if res:\n",
    "                    df = pd.DataFrame(res)\n",
    "                    df.columns = [d[0] for d in cur.description]\n",
    "                else:\n",
    "                    df = pd.DataFrame({})\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T04:40:44.717908Z",
     "start_time": "2022-06-24T04:40:44.683959Z"
    }
   },
   "outputs": [],
   "source": [
    "class Anki(object):\n",
    "    THRESHOLD = 0.15  # Only record similarity values above threshold\n",
    "    PARTIAL = None  # Only look at first n entries\n",
    "    COMPARISON_FUNC = Helpers.intersection_size  # Originally jaccard but that gave iffy results\n",
    "\n",
    "    def __init__(self, file, overwrite=True, read=True, PARTIAL=None):\n",
    "        self.file = os.path.abspath(file)\n",
    "        self.sql = SQL(f'{self.file}.sql')\n",
    "        self.PARTIAL = PARTIAL\n",
    "\n",
    "        self.db = []\n",
    "\n",
    "        self.all_cards = set()\n",
    "        self.all_tags = set()\n",
    "        self.all_imgs = set()\n",
    "        self.n_cards = 0\n",
    "        self.n_tags = 0\n",
    "        self.n_imgs = 0\n",
    "\n",
    "        self.note_sim = {'images': [], 'tags': [], 'text': [], 'overall': []}\n",
    "        self.image_sim = {}\n",
    "        self.tag_sim = {}\n",
    "\n",
    "        if overwrite:\n",
    "            self.sql.init_sql()\n",
    "\n",
    "        if read:\n",
    "            self.read_file()\n",
    "\n",
    "    def read_file(self):\n",
    "        with Apkg(self.file) as apkg:\n",
    "            for ct, card in enumerate(tqdm(apkg, f'Reading `{self.file}`: ',\n",
    "                             total=sum(1 for _ in apkg),\n",
    "                             position=0, leave=True)):\n",
    "\n",
    "                if self.PARTIAL:\n",
    "                    if ct > self.PARTIAL:\n",
    "                        print(ct)\n",
    "                        break\n",
    "                        \n",
    "                note = card['note']\n",
    "                content = dict(zip(note['model']['flds'], note['flds']))\n",
    "\n",
    "                # Extracting images\n",
    "                images = []\n",
    "                for field in ['Text', 'Extra', 'Image', 'Lecture Notes',\n",
    "                              'Missed Questions', 'Pathoma', 'Boards and Beyond',\n",
    "                              'First Aid', 'Sketchy', 'Pixorize', 'Physeo',\n",
    "                              'Additional Resources']:\n",
    "                    imgs = Helpers.get_images(content.get(field))\n",
    "                    if imgs:\n",
    "                        images += imgs\n",
    "\n",
    "                # Regularizing the 'Text' and 'Extra' fields\n",
    "                if 'Text' in content.keys():\n",
    "                    text = Helpers.clean_html_tags(\n",
    "                        Helpers.remove_cloze(content['Text']))\n",
    "                else:\n",
    "                    try:\n",
    "                        text = clean_html_tags(content['Header'])\n",
    "                    except:\n",
    "                        # A few of the in-house psych cards used a weird format\n",
    "                        # Honestly just gonna skip\n",
    "                        continue\n",
    "\n",
    "                if 'Extra' in content.keys():\n",
    "                    extra = Helpers.clean_html_tags(content['Extra'])\n",
    "                else:\n",
    "                    extra = ''\n",
    "\n",
    "                out = {}\n",
    "                out['id'] = note['id']\n",
    "                out['data'] = f'{text} \\n {extra}'\n",
    "                out['images'] = set(images)\n",
    "                out['tags'] = Helpers.telescope_tags(note['tags'])\n",
    "\n",
    "                self.db.append(out)\n",
    "\n",
    "        self.all_cards = set(card['id'] for card in self.db)\n",
    "        self.all_tags = set(tag for taglist in [card['tags']\n",
    "                                                for card in self.db]\n",
    "                            for tag in taglist)\n",
    "        self.all_imgs = set(img for imglist in [card['images']\n",
    "                                                for card in self.db]\n",
    "                            for img in imglist)\n",
    "        self.calculate_n()\n",
    "        self.serialize_sets()\n",
    "\n",
    "#     def compute_note_similarity(self):\n",
    "#         self.note_image_similarity()\n",
    "#         self.note_tag_similarity()\n",
    "#         self.note_text_similarity()\n",
    "#         self.note_overall_similarity()\n",
    "\n",
    "    def calculate_n(self):\n",
    "        self.n_tags = len(self.all_tags)\n",
    "        self.n_cards = len(self.db)\n",
    "        self.n_imgs = len(self.all_imgs)\n",
    "\n",
    "    def serialize_sets(self):\n",
    "        print('Serializing total set of card IDs, images, and tags')\n",
    "        self.sql.insert_vals(f'''\n",
    "                              INSERT INTO cards (card_id)\n",
    "                              VALUES (?)\n",
    "                              ''', self.all_cards)\n",
    "        self.sql.insert_vals(f'''\n",
    "                              INSERT INTO tags (tag)\n",
    "                              VALUES (?)\n",
    "                              ''', self.all_tags)\n",
    "        self.sql.insert_vals(f'''\n",
    "                              INSERT INTO images (image)\n",
    "                              VALUES (?)\n",
    "                              ''', self.all_imgs)\n",
    "\n",
    "    def note_image_similarity(self):\n",
    "        res = self.note_list_similarity('images')\n",
    "        return res\n",
    "\n",
    "    def note_tag_similarity(self):\n",
    "        res = self.note_list_similarity('tags')\n",
    "        return res\n",
    "\n",
    "    def note_text_similarity(self):\n",
    "        pass  # TODO\n",
    "\n",
    "    def note_overall_similarity(self):\n",
    "        pass  # TODO\n",
    "\n",
    "    def note_list_similarity(self, list_type):\n",
    "        assert list_type.lower() in ['images', 'tags']\n",
    "        res = []\n",
    "        represented = []\n",
    "\n",
    "        pairs = itertools.combinations(self.db, 2)\n",
    "        combos = self.n_cards * (self.n_cards - 1) / 2\n",
    "        n = self.n_cards\n",
    "\n",
    "        for pair in tqdm(pairs, f'Calculating similarity of cards by their {list_type}: ',\n",
    "                         total=combos, position=0, leave=True):\n",
    "            sim = Anki.COMPARISON_FUNC(\n",
    "                pair[0][list_type], pair[1][list_type])\n",
    "            if sim > self.THRESHOLD:\n",
    "                card1_id = pair[0]['id']\n",
    "                card2_id = pair[1]['id']\n",
    "                res.append((card1_id, card2_id, sim))\n",
    "                if card1_id not in represented:\n",
    "                    represented.append(card1_id)\n",
    "                if card2_id not in represented:\n",
    "                    represented.append(card2_id)\n",
    "\n",
    "        print(f'{n} cards total. {len(represented)} cards represented in matrix '\n",
    "              f'({100*len(represented)/n:.2f}%). '\n",
    "              f'At theshold {self.THRESHOLD}, storing {len(res)} of {combos} combos '\n",
    "              f'of {list_type} ({100*(1-len(res)/combos):.2f}% reduction)')\n",
    "\n",
    "        tbl = list_type[:-1]\n",
    "        print(f'Serializing results into table note_{tbl}_sim')\n",
    "        self.serialize_note_similarity(tbl, res)\n",
    "        return res\n",
    "    \n",
    "    def tag_similarity(self):\n",
    "        res = {}\n",
    "        for card in tqdm(self.db, f'Calculating similarity of tags: ',\n",
    "                         total=self.n_cards, position=0, leave=True):\n",
    "            tag_lst = sorted(card['tags'])\n",
    "            n_tag_lst = len(tag_lst)\n",
    "            combos = n_tag_lst * (n_tag_lst - 1) / 2\n",
    "            \n",
    "            for tag_pair in itertools.combinations(tag_lst, 2):\n",
    "                key = f'{tag_pair[0]}\\t{tag_pair[1]}'\n",
    "                if key not in res.keys():\n",
    "                    res[key] = [[],[]]\n",
    "                \n",
    "                \n",
    "                res[key][0].append(card['id'])\n",
    "                res[key][1].append(card['id'])\n",
    "                \n",
    "        out = []\n",
    "        represented = set()\n",
    "        for tag_pair, id_lists in tqdm(res.items(), 'Reducing tag list to similarity metric: ',\n",
    "                                      total = len(res), position=0, leave=True):\n",
    "            splt = tag_pair.split('\\t')\n",
    "            tag1 = splt[0]\n",
    "            tag2 = splt[1]\n",
    "            sim = Anki.COMPARISON_FUNC(*id_lists)\n",
    "            \n",
    "            if sim != 0:\n",
    "                out.append((tag1, tag2, sim))\n",
    "                if tag1 not in represented:\n",
    "                    represented.add(tag1)\n",
    "                if tag2 not in represented:\n",
    "                    represented.add(tag2)\n",
    "                    \n",
    "        print(f'{self.n_tags} tags total. {len(represented)} tags represented in matrix '\n",
    "              f'({100*len(represented)/self.n_tags:.2f}%). '\n",
    "              f'Storing {len(out)} nonzero values of {len(res)} tag combos '\n",
    "              f'({100*(1-len(out)/len(res)):.2f}% reduction).')\n",
    "        print('Serializing tag similarity')\n",
    "        self.sql.insert_vals(f'''\n",
    "                              INSERT INTO tag_sim (tag_a, tag_b, value)\n",
    "                              VALUES (?, ?, ?)\n",
    "                              ''', out)\n",
    "        \n",
    "    def image_similarity(self):\n",
    "        res = {}\n",
    "        for card in tqdm(self.db, f'Calculating similarity of images: ',\n",
    "                         total=self.n_cards, position=0, leave=True):\n",
    "            img_lst = sorted(card['images'])\n",
    "            n_img_lst = len(img_lst)\n",
    "            combos = n_img_lst * (n_img_lst - 1) / 2\n",
    "            \n",
    "            for img_pair in itertools.combinations(img_lst, 2):\n",
    "                key = f'{img_pair[0]}\\t{img_pair[1]}'\n",
    "                if key not in res.keys():\n",
    "                    res[key] = [[],[]]\n",
    "                \n",
    "                res[key][0].append(card['id'])\n",
    "                res[key][1].append(card['id'])\n",
    "                \n",
    "        out = []\n",
    "        represented = set()\n",
    "        for img_pair, id_lists in tqdm(res.items(), 'Reducing image list to similarity metric: ',\n",
    "                                      total = len(res), position=0, leave=True):\n",
    "            splt = img_pair.split('\\t')\n",
    "            img1 = splt[0]\n",
    "            img2 = splt[1]\n",
    "            sim = Anki.COMPARISON_FUNC(*id_lists)\n",
    "            \n",
    "            if sim != 0:\n",
    "                out.append((img1, img2, sim))\n",
    "                if img1 not in represented:\n",
    "                    represented.add(img1)\n",
    "                if img2 not in represented:\n",
    "                    represented.add(img2)\n",
    "                    \n",
    "        print(f'{self.n_imgs} images total. {len(represented)} images represented in matrix '\n",
    "              f'({100*len(represented)/self.n_imgs:.2f}%). '\n",
    "              f'Storing {len(out)} nonzero values of {len(res)} tag combos '\n",
    "              f'({100*(1-len(out)/len(res)):.2f}% reduction).')\n",
    "        print('Serializing image similarity')\n",
    "        self.sql.insert_vals(f'''\n",
    "                              INSERT INTO image_sim (image_a, image_b, value)\n",
    "                              VALUES (?, ?, ?)\n",
    "                              ''', out)\n",
    "\n",
    "#     # idc if I'm repeating myself in these next two funcs\n",
    "#     def tag_similarity_old(self):\n",
    "#         pairs = itertools.combinations(self.all_tags, 2)\n",
    "#         combos = self.n_tags * (self.n_tags - 1) / 2\n",
    "\n",
    "#         res = []\n",
    "#         represented = []\n",
    "#         for pair in tqdm(pairs, f'Calculating similarity of tags: ',\n",
    "#                          total=combos, position=0, leave=True):\n",
    "#             tag1 = pair[0]\n",
    "#             tag2 = pair[1]\n",
    "#             tag1_cards = [card['id']\n",
    "#                           for card in self.db \n",
    "#                           if tag1 in card['tags']]\n",
    "#             tag2_cards = [card['id']\n",
    "#                           for card in self.db \n",
    "#                           if tag2 in card['tags']]\n",
    "#             sim = Anki.COMPARISON_FUNC(tag1_cards, tag2_cards)\n",
    "\n",
    "#             if sim != 0:\n",
    "#                 res.append((tag1, tag2, sim))\n",
    "#                 if tag1 not in represented:\n",
    "#                     represented.append(tag1)\n",
    "#                 if tag2 not in represented:\n",
    "#                     represented.append(tag2)\n",
    "\n",
    "#         print(f'{self.n_tags} tags total. {len(represented)} tags represented in matrix '\n",
    "#               f'({100*len(represented)/self.n_tags:.2f}%). '\n",
    "#               f'Storing {len(res)} nonzero values of {combos} tag combos '\n",
    "#               f'({100*(1-len(res)/combos):.2f}% reduction).')\n",
    "#         print('Serializing tag similarity')\n",
    "#         self.sql.insert_vals(f'''\n",
    "#                               INSERT INTO tag_sim (tag_a, tag_b, value)\n",
    "#                               VALUES (?, ?, ?)\n",
    "#                               ''', res)\n",
    "#         return res\n",
    "\n",
    "#     def image_similarity(self):\n",
    "#         pairs = itertools.combinations(self.all_imgs, 2)\n",
    "#         combos = self.n_imgs * (self.n_imgs - 1) / 2\n",
    "\n",
    "#         res = []\n",
    "#         represented = []\n",
    "#         for pair in tqdm(pairs, f'Calculating similarity of images: ',\n",
    "#                          total=combos, position=0, leave=True):\n",
    "#             img1 = pair[0]\n",
    "#             img2 = pair[1]\n",
    "#             img1_cards = [card['id']\n",
    "#                           for card in self.db \n",
    "#                           if img1 in card['images']]\n",
    "#             img2_cards = [card['id']\n",
    "#                           for card in self.db \n",
    "#                           if img2 in card['images']]\n",
    "#             sim = Anki.COMPARISON_FUNC(img1_cards, img2_cards)\n",
    "\n",
    "#             if sim != 0:\n",
    "#                 res.append((img1, img2, sim))\n",
    "#                 if img1 not in represented:\n",
    "#                     represented.append(img1)\n",
    "#                 if img2 not in represented:\n",
    "#                     represented.append(img2)\n",
    "\n",
    "#         print(f'{self.n_imgs} total. {len(represented)} images represented in matrix '\n",
    "#               f'({100*len(represented)/self.n_imgs:.2f}%). '\n",
    "#               f'Storing {len(res)} nonzero values of {combos} image combos '\n",
    "#               f'({100*(1-len(res)/combos):.2f}% reduction).')\n",
    "#         print('Serializing image similarity')\n",
    "#         self.sql.insert_vals(f'''\n",
    "#                               INSERT INTO image_sim (image_a, image_b, value)\n",
    "#                               VALUES (?, ?, ?)\n",
    "#                               ''', res)\n",
    "#         return res\n",
    "\n",
    "    def serialize_note_similarity(self, table, params):\n",
    "        self.sql.insert_vals(f'''\n",
    "                              INSERT INTO note_{table}_sim (card_a, card_b, value)\n",
    "                              VALUES (?, ?, ?)\n",
    "                              ''', params)\n",
    "\n",
    "    def load_from_db(self):\n",
    "        print(f'Loading from database {self.sql.path}')\n",
    "\n",
    "        self.all_cards = set(self.sql.execute('SELECT * FROM cards')['card_id'])\n",
    "        self.all_tags = set(self.sql.execute('SELECT * FROM tags')['tag'])\n",
    "        self.all_imgs = set(self.sql.execute('SELECT * FROM images')['image'])\n",
    "        self.calculate_n()\n",
    "\n",
    "        self.note_sim['images'] = self.sql.execute(\n",
    "            'SELECT * from note_image_sim;')\n",
    "        self.note_sim['tags'] = self.sql.execute('SELECT * from note_tag_sim;')\n",
    "        self.note_sim['text'] = self.sql.execute(\n",
    "            'SELECT * from note_text_sim;')\n",
    "        self.note_sim['overall'] = self.sql.execute(\n",
    "            'SELECT * from note_overall_sim;')\n",
    "        self.tag_sim = self.sql.execute('SELECT * from tag_sim;')\n",
    "        self.image_sim = self.sql.execute('SELECT * from image_sim;')\n",
    "\n",
    "    def set_threshold(self, threshold=0.15):\n",
    "        self.THRESHOLD = threshold\n",
    "        \n",
    "\n",
    "# TODO: Calculate similarity based on text\n",
    "# TODO: Calculate network fusion\n",
    "\n",
    "# TODO: combine all the whitespace? Handle punctuation?\n",
    "# TODO: use executemany() to improve serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T04:40:47.450334Z",
     "start_time": "2022-06-24T04:40:47.447716Z"
    }
   },
   "outputs": [],
   "source": [
    "file = 'Selected Notes.apkg' # Selected Notes.apkg or Subset.apkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T04:43:36.511099Z",
     "start_time": "2022-06-24T04:40:53.995334Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading `/mnt/c/Users/edrid.EDRIDGE-DSOUZA-/Documents/GitHub/anki-network/Selected Notes.apkg`:  29%|██▉       | 5001/17052 [00:07<00:18, 659.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001\n",
      "Serializing total set of card IDs, images, and tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 3830/3830 [00:00<00:00, 11868.30it/s]\n",
      "Serializing: 100%|██████████| 514/514 [00:00<00:00, 3343.46it/s]\n",
      "Serializing: 100%|██████████| 4640/4640 [00:01<00:00, 2797.14it/s]\n",
      "Calculating similarity of cards by their images: 100%|██████████| 12502500/12502500.0 [00:18<00:00, 662855.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001 cards total. 3718 cards represented in matrix (74.35%). At theshold 0.001, storing 133665 of 12502500.0 combos of images (98.93% reduction)\n",
      "Serializing results into table note_image_sim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 133665/133665 [00:02<00:00, 49736.41it/s]\n",
      "Calculating similarity of cards by their tags: 100%|██████████| 12502500/12502500.0 [01:08<00:00, 181954.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001 cards total. 3756 cards represented in matrix (75.10%). At theshold 9.5, storing 1269172 of 12502500.0 combos of tags (89.85% reduction)\n",
      "Serializing results into table note_tag_sim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 1269172/1269172 [00:43<00:00, 29427.78it/s]\n",
      "Calculating similarity of tags: 100%|██████████| 5001/5001 [00:00<00:00, 9110.92it/s] \n",
      "Reducing tag list to similarity metric: 100%|██████████| 19361/19361 [00:00<00:00, 180227.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514 tags total. 514 tags represented in matrix (100.00%). Storing 19361 nonzero values of 19361 tag combos (0.00% reduction).\n",
      "Serializing tag similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 19361/19361 [00:04<00:00, 4753.22it/s]\n",
      "Calculating similarity of images: 100%|██████████| 5001/5001 [00:00<00:00, 107317.36it/s]\n",
      "Reducing image list to similarity metric: 100%|██████████| 18679/18679 [00:00<00:00, 108357.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4640 images total. 4604 images represented in matrix (99.22%). Storing 18679 nonzero values of 18679 tag combos (0.00% reduction).\n",
      "Serializing image similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 18679/18679 [00:00<00:00, 106356.09it/s]\n"
     ]
    }
   ],
   "source": [
    "x = Anki(file, overwrite=False, PARTIAL=5000)\n",
    "\n",
    "x.set_threshold(0.001)  # Record nonzero similarity\n",
    "x.note_image_similarity()\n",
    "\n",
    "x.set_threshold(9.5)  # Only record similarity if a tag shares 10+ notes. Real distribution prob more valuable if > 5\n",
    "x.note_tag_similarity()\n",
    "\n",
    "# x.note_text_similarity()\n",
    "# x.note_overall_similarity()\n",
    "x.tag_similarity()\n",
    "x.image_similarity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:54:12.044816Z",
     "start_time": "2022-06-24T14:26:22.646Z"
    }
   },
   "outputs": [],
   "source": [
    "x.db[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:54:12.047248Z",
     "start_time": "2022-06-24T14:26:22.647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reload the file and ensure the proper info was saved to the db\n",
    "x = Anki(file, overwrite=False, read=False)\n",
    "x.load_from_db()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:54:12.048714Z",
     "start_time": "2022-06-24T14:26:22.649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Doc2Vec for similarity scores:\n",
    "# https://medium.com/red-buffer/doc2vec-computing-similarity-between-the-documents-47daf6c828cd\n",
    "# https://stackoverflow.com/questions/53503049/measure-similarity-between-two-documents-using-doc2vec\n",
    "# https://github.com/jhlau/doc2vec#pre-trained-doc2vec-models\n",
    "\n",
    "# https://github.com/rmarkello/snfpy to fuse similarity networks\n",
    "# https://github.com/maxconway/SNFtool has more visualization options\n",
    "# sklearn to do general network stuff\n",
    "# https://towardsdatascience.com/visualising-similarity-clusters-with-interactive-graphs-20a4b2a18534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:54:12.049787Z",
     "start_time": "2022-06-24T14:26:22.651Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm, Normalize\n",
    "\n",
    "all_tags = list(x.all_tags)\n",
    "sim = x.tag_sim.copy()\n",
    "sim.tag_a = sim.tag_a.map(lambda tag: all_tags.index(tag))\n",
    "sim.tag_b = sim.tag_b.map(lambda tag: all_tags.index(tag))\n",
    "\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "tmp = coo_matrix((sim.value, (sim.tag_a, sim.tag_b)), shape=(440, 440)).toarray()\n",
    "\n",
    "sns.clustermap(tmp + 0.0001, norm=LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:54:12.051438Z",
     "start_time": "2022-06-24T14:26:22.653Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import seaborn as sns\n",
    "\n",
    "all_images = list(x.all_imgs)\n",
    "sim = x.image_sim.copy()\n",
    "sim.image_a = sim.image_a.map(lambda img: all_images.index(img))\n",
    "sim.image_b = sim.image_b.map(lambda img: all_images.index(img))\n",
    "\n",
    "\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "tmp = coo_matrix((sim.value, (sim.image_a, sim.image_b)), shape=(len(all_images), len(all_images))).toarray()\n",
    "\n",
    "sns.clustermap(tmp + 0.0001,norm=LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:54:12.053056Z",
     "start_time": "2022-06-24T14:26:22.654Z"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.from_numpy_matrix(tmp)\n",
    "nx.draw_spring(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-24T02:54:12.055289Z",
     "start_time": "2022-06-24T14:26:22.656Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "from scipy import spatial\n",
    "\n",
    "d2v_model = doc2vec.Doc2Vec.load(model_file)\n",
    "\n",
    "fisrt_text = '..'\n",
    "second_text = '..'\n",
    "\n",
    "vec1 = d2v_model.infer_vector(fisrt_text.split())\n",
    "vec2 = d2v_model.infer_vector(second_text.split())\n",
    "\n",
    "cos_distance = spatial.distance.cosine(vec1, vec2)\n",
    "# cos_distance indicates how much the two texts differ from each other:\n",
    "# higher values mean more distant (i.e. different) texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
