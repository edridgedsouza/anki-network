{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T15:59:24.912623Z",
     "start_time": "2022-06-23T15:59:24.639782Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T15:59:25.215342Z",
     "start_time": "2022-06-23T15:59:24.914401Z"
    }
   },
   "outputs": [],
   "source": [
    "from ankisync2 import Apkg\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import math\n",
    "import sqlite3\n",
    "from contextlib import closing\n",
    "import pandas as pd\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T16:02:17.522245Z",
     "start_time": "2022-06-23T16:02:17.485669Z"
    }
   },
   "outputs": [],
   "source": [
    "class Anki(object):\n",
    "    THRESHOLD = 0.15  # Only record similarity values above threshold\n",
    "    PARTIAL = None  # Only look at first n entries\n",
    "    DELAY = 0.5  # Just for display purposes\n",
    "    \n",
    "    def __init__(self, file, overwrite=True, read=True):\n",
    "        self.file = os.path.abspath(file)\n",
    "        self.sql = f'{self.file}.sql'\n",
    "        self.db = []\n",
    "        self.note_sim = {'images': [], 'tags': [], 'text': [], 'overall': []}  # Empty until we need it\n",
    "        self.image_sim = {}\n",
    "        self.tag_sim = {}\n",
    "        \n",
    "        if overwrite:\n",
    "            self.init_sql()\n",
    "            \n",
    "        if read:\n",
    "            self.read_file()\n",
    "        \n",
    "    def read_file(self):\n",
    "        with Apkg(self.file) as apkg:\n",
    "            for card in tqdm(apkg, f'Reading `{self.file}`: ', \n",
    "                             total=sum(1 for _ in apkg), \n",
    "                             position=0, leave=True):\n",
    "\n",
    "                note = card['note']\n",
    "                content = dict(zip(note['model']['flds'], note['flds']))\n",
    "\n",
    "                # Extracting images\n",
    "                images = []\n",
    "                for field in ['Text', 'Extra', 'Image', 'Lecture Notes', \n",
    "                              'Missed Questions', 'Pathoma', 'Boards and Beyond', \n",
    "                              'First Aid', 'Sketchy', 'Pixorize', 'Physeo', \n",
    "                              'Additional Resources']:\n",
    "                    imgs = Anki.get_images(content.get(field))\n",
    "                    if imgs:\n",
    "                        images += imgs\n",
    "\n",
    "                # Regularizing the 'Text' and 'Extra' fields\n",
    "                if 'Text' in content.keys():\n",
    "                    text = Anki.clean_html_tags(Anki.remove_cloze(content['Text']))\n",
    "                else:\n",
    "                    try:\n",
    "                        text = clean_html_tags(content['Header'])\n",
    "                    except:\n",
    "                        # A few of the in-house psych cards used a weird format\n",
    "                        # Honestly just gonna skip\n",
    "                        continue\n",
    "                        \n",
    "                if 'Extra' in content.keys():\n",
    "                    extra = Anki.clean_html_tags(content['Extra'])\n",
    "                else:\n",
    "                    extra = ''\n",
    "\n",
    "                out = {}\n",
    "                out['id'] = note['id']\n",
    "                out['data'] = f'{text} \\n {extra}'\n",
    "                out['images'] = list(set(images))\n",
    "                out['tags'] = Anki.telescope_tags(note['tags'])\n",
    "\n",
    "                self.db.append(out)\n",
    "        self.n_cards = len(self.db)\n",
    "        \n",
    "#     def compute_note_similarity(self):\n",
    "#         self.note_image_similarity()\n",
    "#         self.note_tag_similarity()\n",
    "#         self.note_text_similarity()\n",
    "#         self.note_overall_similarity()\n",
    "\n",
    "    def note_image_similarity(self):\n",
    "        res = self.note_list_similarity('images')\n",
    "        return res\n",
    "    \n",
    "    def note_tag_similarity(self):\n",
    "        res = self.note_list_similarity('tags')\n",
    "        return res\n",
    "    \n",
    "    def note_text_similarity(self):\n",
    "        pass # TODO\n",
    "    \n",
    "    def note_overall_similarity(self):\n",
    "        pass # TODO\n",
    "    \n",
    "    def note_list_similarity(self, list_type):\n",
    "        assert list_type.lower() in ['images', 'tags']\n",
    "        res = []\n",
    "\n",
    "        if self.PARTIAL:\n",
    "            pairs = itertools.permutations(self.db[0:self.PARTIAL], 2)\n",
    "            perms = int(math.factorial(self.PARTIAL)/math.factorial(self.PARTIAL-2))\n",
    "        else:\n",
    "            pairs = itertools.permutations(self.db, 2)\n",
    "            perms = int(math.factorial(self.n_cards)/math.factorial(self.n_cards-2))\n",
    "        \n",
    "        for pair in tqdm(pairs, f'Calculating similarity of cards by their {list_type}: ',\n",
    "                         total = perms, position=0, leave=True):\n",
    "            sim = Anki.jaccard_similarity(pair[0][list_type], pair[1][list_type])\n",
    "            if sim > self.THRESHOLD:\n",
    "                res.append((pair[0]['id'], pair[1]['id'], sim))\n",
    "\n",
    "        print(f'At theshold {self.THRESHOLD}, storing {len(res)} of {perms} combos '\n",
    "              f'of {list_type} ({100*(1-len(res)/perms):.2f}% reduction)')\n",
    "        \n",
    "        tbl = list_type[:-1]\n",
    "        print(f'Serializing results into table note_{tbl}_sim')\n",
    "        self.serialize_note_similarity(tbl, res)\n",
    "        return res\n",
    "    \n",
    "    # idc if I'm repeating myself in these next two funcs\n",
    "    def tag_similarity(self):\n",
    "        all_tags = list(set(tag for taglist in [card['tags'] for card in self.db] for tag in taglist))\n",
    "        n_tags = len(all_tags)\n",
    "        \n",
    "        pairs = itertools.permutations(all_tags, 2)\n",
    "        perms = int(math.factorial(n_tags)/math.factorial(n_tags-2))\n",
    "        \n",
    "        res = []\n",
    "        for pair in tqdm(pairs, f'Calculating similarity of tags: ',\n",
    "                         total = perms, position=0, leave=True):\n",
    "            tag1 = pair[0]\n",
    "            tag2 = pair[1]\n",
    "            tag1_cards = [card['id'] for card in self.db if tag1 in card['tags']]\n",
    "            tag2_cards = [card['id'] for card in self.db if tag2 in card['tags']]\n",
    "            sim = Anki.jaccard_similarity(tag1_cards, tag2_cards)\n",
    "            \n",
    "            if sim != 0:\n",
    "                res.append((tag1, tag2, sim))\n",
    "                \n",
    "        print(f'Storing {len(res)} of {perms} combinations of tags '\n",
    "              f'({100*(1-len(res)/perms):.2f}% reduction).')\n",
    "        print('Serializing tag similarity')\n",
    "        self.insert_multiple_vals(f'''\n",
    "                                  INSERT INTO tag_sim (tag_a, tag_b, value)\n",
    "                                  VALUES (?, ?, ?)\n",
    "                                   ''', res)\n",
    "        return res\n",
    "    \n",
    "    def image_similarity(self):\n",
    "        all_imgs = list(set(img for imglist in [card['images'] for card in self.db] for img in imglist))\n",
    "        n_imgs = len(all_imgs)\n",
    "        \n",
    "        pairs = itertools.permutations(all_imgs, 2)\n",
    "        perms = int(math.factorial(n_imgs)/math.factorial(n_imgs-2))\n",
    "        \n",
    "        res = []\n",
    "        for pair in tqdm(pairs, f'Calculating similarity of images: ',\n",
    "                         total = perms, position=0, leave=True):\n",
    "            img1 = pair[0]\n",
    "            img2 = pair[1]\n",
    "            img1_cards = [card['id'] for card in self.db if img1 in card['tags']]\n",
    "            img2_cards = [card['id'] for card in self.db if img2 in card['tags']]\n",
    "            sim = Anki.jaccard_similarity(img1_cards, img2_cards)\n",
    "            \n",
    "            if sim != 0:\n",
    "                res.append((img1, img2, sim))\n",
    "                \n",
    "        print(f'Storing {len(res)} of {perms} combinations of images '\n",
    "              f'({100*(1-len(res)/perms):.2f}% reduction).')\n",
    "        print('Serializing image similarity')\n",
    "        self.insert_multiple_vals(f'''\n",
    "                                  INSERT INTO image_sim (image_a, image_b, value)\n",
    "                                  VALUES (?, ?, ?)\n",
    "                                   ''', res)\n",
    "        return res\n",
    "            \n",
    "    \n",
    "    def init_sql(self):\n",
    "        print(f'Creating new storage db at {self.sql}')\n",
    "        conn = sqlite3.connect(self.sql)\n",
    "        cursor = conn.cursor()\n",
    "        for tbl in ['note_image_sim', 'note_tag_sim', 'note_text_sim', 'note_overall_sim',\n",
    "                    'tag_sim', 'image_sim']:\n",
    "            cursor.execute(f'DROP TABLE IF EXISTS {tbl}')\n",
    "            \n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_image_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_image_sim_idx ON note_image_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_tag_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_tag_sim_idx ON note_tag_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_text_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_text_sim_idx ON note_text_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_overall_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_overall_sim_idx ON note_overall_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE tag_sim\n",
    "                       (tag_a string, \n",
    "                       tag_b string,\n",
    "                       value real);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX tag_sim_idx ON tag_sim (tag_a, tag_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE image_sim\n",
    "                       (image_a string, \n",
    "                       image_b string,\n",
    "                       value real);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX image_sim_idx ON image_sim (image_a, image_b);')\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "    def execute_sql(self, sql, params=()):\n",
    "        with closing(sqlite3.connect(self.sql)) as conn:\n",
    "            with conn:\n",
    "                cur = conn.cursor()\n",
    "                try:\n",
    "                    cur.execute(sql, params)\n",
    "                    res = cur.fetchall()\n",
    "                except sqlite3.ProgrammingError:\n",
    "                    print(f'SQL:\\n{sql}\\n{params}')\n",
    "\n",
    "                if res:\n",
    "                    df = pd.DataFrame(res)\n",
    "                    df.columns = [d[0] for d in cur.description]\n",
    "                else:\n",
    "                    df = pd.DataFrame({})\n",
    "        return df\n",
    "    \n",
    "    def insert_multiple_vals(self, sql, param_list):\n",
    "        with closing(sqlite3.connect(self.sql)) as conn:\n",
    "            with conn:\n",
    "                cur = conn.cursor()\n",
    "                try:\n",
    "                    sleep(self.DELAY)\n",
    "                    for params in tqdm(param_list, 'Serializing', position=0, leave=True):\n",
    "                        cur.execute(sql, params)\n",
    "                    res = cur.fetchall()\n",
    "                except sqlite3.ProgrammingError:\n",
    "                    print(f'SQL:\\n{sql}\\n{params}')\n",
    "\n",
    "                if res:\n",
    "                    df = pd.DataFrame(res)\n",
    "                    df.columns = [d[0] for d in cur.description]\n",
    "                else:\n",
    "                    df = pd.DataFrame({})\n",
    "        return df\n",
    "        \n",
    "    def serialize_note_similarity(self, table, params):\n",
    "        self.insert_multiple_vals(f'''\n",
    "                                  INSERT INTO note_{table}_sim (post_a, post_b, value)\n",
    "                                  VALUES (?, ?, ?)\n",
    "                                   ''', params)\n",
    "    \n",
    "    def load_from_db(self):\n",
    "        print(f'Loading from database {self.sql}')\n",
    "        self.note_sim['images'] = self.execute_sql('SELECT * from note_image_sim;')\n",
    "        self.note_sim['tags'] = self.execute_sql('SELECT * from note_tag_sim;')\n",
    "        self.note_sim['text'] = self.execute_sql('SELECT * from note_text_sim;')\n",
    "        self.note_sim['overall'] = self.execute_sql('SELECT * from note_overall_sim;')\n",
    "        self.tag_sim = self.execute_sql('SELECT * from tag_sim;')\n",
    "        self.image_sim = self.execute_sql('SELECT * from image_sim;')\n",
    "    \n",
    "    def set_threshold(self, threshold=0.15):\n",
    "        self.THRESHOLD = threshold\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_html_tags(markup):\n",
    "        soup = BeautifulSoup(markup, 'html.parser')\n",
    "        for br in soup.find_all('br'):\n",
    "            br.replace_with('\\n')\n",
    "        return soup.get_text()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_images(markup):\n",
    "        out = []\n",
    "        if markup:\n",
    "            soup = BeautifulSoup(markup, 'html.parser')\n",
    "            images = soup.findAll('img')\n",
    "            for image in images:\n",
    "                out.append(image['src'])  \n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_cloze(markup):\n",
    "        # txt = '<a href=\"blah\"> Hello {{c1::world}} once {{c2::again::hint}} lol </a>'\n",
    "        return re.sub('{{.*?::(.*?)(::.*?){0,}}}', '\\\\1', markup)\n",
    "    \n",
    "    @staticmethod\n",
    "    def telescope_tags(taglist):\n",
    "        out = []\n",
    "        for tag in taglist:\n",
    "            splt = tag.lower().split('::')\n",
    "            for i in range(1, len(splt)):\n",
    "                out.append('::'.join(splt[0:i]))\n",
    "        return list(set(out))\n",
    "\n",
    "    @staticmethod\n",
    "    def jaccard_similarity(list1, list2):\n",
    "        s1 = set(list1)\n",
    "        s2 = set(list2)\n",
    "        try:\n",
    "            jaccard = float(len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "        except ZeroDivisionError:\n",
    "            jaccard = 0\n",
    "        return jaccard\n",
    "\n",
    "# TODO: Calculate similarity based on text\n",
    "# TODO: Calculate network fusion\n",
    "\n",
    "# TODO: combine all the whitespace?\n",
    "# TODO: similarity of tags/images rather than notes \n",
    "# (easier to compute: simply count how many notes any 2 tags have in common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-23T16:02:21.058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new storage db at /mnt/c/Users/edrid.EDRIDGE-DSOUZA-/Documents/GitHub/anki-network/Subset.apkg.sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading `/mnt/c/Users/edrid.EDRIDGE-DSOUZA-/Documents/GitHub/anki-network/Subset.apkg`: 100%|██████████| 572/572 [00:01<00:00, 573.70it/s]\n",
      "Calculating similarity of cards by their images: 100%|██████████| 284622/284622 [00:00<00:00, 693303.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At theshold 0.15, storing 2098 of 284622 combos of images (99.26% reduction)\n",
      "Serializing results into table note_image_sim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 2098/2098 [00:00<00:00, 62891.48it/s]\n",
      "Calculating similarity of cards by their tags: 100%|██████████| 284622/284622 [00:00<00:00, 309967.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At theshold 0.15, storing 136468 of 284622 combos of tags (52.05% reduction)\n",
      "Serializing results into table note_tag_sim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 136468/136468 [00:00<00:00, 170592.13it/s]\n",
      "Calculating similarity of tags:   0%|          | 0/193160 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "x = Anki(\"Subset.apkg\")  # Selected Notes.apkg\n",
    "x.set_threshold(0.15)\n",
    "x.note_image_similarity()\n",
    "x.note_tag_similarity()\n",
    "# x.note_text_similarity()\n",
    "# x.note_overall_similarity()\n",
    "x.tag_similarity()\n",
    "x.image_similarity()\n",
    "x = Anki(\"Subset.apkg\", overwrite=False, read=False)\n",
    "x.load_from_db()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T16:00:47.462215Z",
     "start_time": "2022-06-23T15:59:25.186Z"
    }
   },
   "outputs": [],
   "source": [
    "x.db[101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T16:00:47.463901Z",
     "start_time": "2022-06-23T15:59:25.189Z"
    }
   },
   "outputs": [],
   "source": [
    "# Doc2Vec for similarity scores:\n",
    "# https://medium.com/red-buffer/doc2vec-computing-similarity-between-the-documents-47daf6c828cd\n",
    "# https://stackoverflow.com/questions/53503049/measure-similarity-between-two-documents-using-doc2vec\n",
    "# https://github.com/jhlau/doc2vec#pre-trained-doc2vec-models\n",
    "\n",
    "# https://github.com/rmarkello/snfpy to fuse similarity networks\n",
    "# https://github.com/maxconway/SNFtool has more visualization options\n",
    "# sklearn to do general network stuff\n",
    "# https://towardsdatascience.com/visualising-similarity-clusters-with-interactive-graphs-20a4b2a18534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T16:00:47.466395Z",
     "start_time": "2022-06-23T15:59:25.192Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "from scipy import spatial\n",
    "\n",
    "d2v_model = doc2vec.Doc2Vec.load(model_file)\n",
    "\n",
    "fisrt_text = '..'\n",
    "second_text = '..'\n",
    "\n",
    "vec1 = d2v_model.infer_vector(fisrt_text.split())\n",
    "vec2 = d2v_model.infer_vector(second_text.split())\n",
    "\n",
    "cos_distance = spatial.distance.cosine(vec1, vec2)\n",
    "# cos_distance indicates how much the two texts differ from each other:\n",
    "# higher values mean more distant (i.e. different) texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
