{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T16:33:49.755164Z",
     "start_time": "2022-06-23T16:33:49.518582Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T16:33:49.980261Z",
     "start_time": "2022-06-23T16:33:49.757326Z"
    }
   },
   "outputs": [],
   "source": [
    "from ankisync2 import Apkg\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import itertools\n",
    "import math\n",
    "import sqlite3\n",
    "from contextlib import closing\n",
    "from time import sleep\n",
    "\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:32:08.467369Z",
     "start_time": "2022-06-23T18:32:08.440399Z"
    }
   },
   "outputs": [],
   "source": [
    "class Anki(object):\n",
    "    THRESHOLD = 0.15  # Only record similarity values above threshold\n",
    "    PARTIAL = None  # Only look at first n entries\n",
    "    \n",
    "    def __init__(self, file, overwrite=True, read=True):\n",
    "        self.file = os.path.abspath(file)\n",
    "        self.sql = SQL(f'{self.file}.sql')\n",
    "        self.db = []\n",
    "        self.note_sim = {'images': [], 'tags': [], 'text': [], 'overall': []}  # Empty until we need it\n",
    "        self.image_sim = {}\n",
    "        self.tag_sim = {}\n",
    "        \n",
    "        if overwrite:\n",
    "            self.sql.init_sql()\n",
    "            \n",
    "        if read:\n",
    "            self.read_file()\n",
    "        \n",
    "    def read_file(self):\n",
    "        with Apkg(self.file) as apkg:\n",
    "            for card in tqdm(apkg, f'Reading `{self.file}`: ', \n",
    "                             total=sum(1 for _ in apkg), \n",
    "                             position=0, leave=True):\n",
    "\n",
    "                note = card['note']\n",
    "                content = dict(zip(note['model']['flds'], note['flds']))\n",
    "\n",
    "                # Extracting images\n",
    "                images = []\n",
    "                for field in ['Text', 'Extra', 'Image', 'Lecture Notes', \n",
    "                              'Missed Questions', 'Pathoma', 'Boards and Beyond', \n",
    "                              'First Aid', 'Sketchy', 'Pixorize', 'Physeo', \n",
    "                              'Additional Resources']:\n",
    "                    imgs = Helpers.get_images(content.get(field))\n",
    "                    if imgs:\n",
    "                        images += imgs\n",
    "\n",
    "                # Regularizing the 'Text' and 'Extra' fields\n",
    "                if 'Text' in content.keys():\n",
    "                    text = Helpers.clean_html_tags(Helpers.remove_cloze(content['Text']))\n",
    "                else:\n",
    "                    try:\n",
    "                        text = clean_html_tags(content['Header'])\n",
    "                    except:\n",
    "                        # A few of the in-house psych cards used a weird format\n",
    "                        # Honestly just gonna skip\n",
    "                        continue\n",
    "                        \n",
    "                if 'Extra' in content.keys():\n",
    "                    extra = Helpers.clean_html_tags(content['Extra'])\n",
    "                else:\n",
    "                    extra = ''\n",
    "\n",
    "                out = {}\n",
    "                out['id'] = note['id']\n",
    "                out['data'] = f'{text} \\n {extra}'\n",
    "                out['images'] = set(images)\n",
    "                out['tags'] = Helpers.telescope_tags(note['tags'])\n",
    "\n",
    "                self.db.append(out)\n",
    "        self.n_cards = len(self.db)\n",
    "        \n",
    "#     def compute_note_similarity(self):\n",
    "#         self.note_image_similarity()\n",
    "#         self.note_tag_similarity()\n",
    "#         self.note_text_similarity()\n",
    "#         self.note_overall_similarity()\n",
    "\n",
    "    def note_image_similarity(self):\n",
    "        res = self.note_list_similarity('images')\n",
    "        return res\n",
    "    \n",
    "    def note_tag_similarity(self):\n",
    "        res = self.note_list_similarity('tags')\n",
    "        return res\n",
    "    \n",
    "    def note_text_similarity(self):\n",
    "        pass # TODO\n",
    "    \n",
    "    def note_overall_similarity(self):\n",
    "        pass # TODO\n",
    "    \n",
    "    def note_list_similarity(self, list_type):\n",
    "        assert list_type.lower() in ['images', 'tags']\n",
    "        res = []\n",
    "        represented = []\n",
    "\n",
    "        if self.PARTIAL:\n",
    "            pairs = itertools.permutations(self.db[0:self.PARTIAL], 2)\n",
    "            perms = int(math.factorial(self.PARTIAL)/math.factorial(self.PARTIAL-2))\n",
    "            n = self.PARTIAL\n",
    "        else:\n",
    "            pairs = itertools.permutations(self.db, 2)\n",
    "            perms = int(math.factorial(self.n_cards)/math.factorial(self.n_cards-2))\n",
    "            n = self.n_cards\n",
    "        \n",
    "        for pair in tqdm(pairs, f'Calculating similarity of cards by their {list_type}: ',\n",
    "                         total = perms, position=0, leave=True):\n",
    "            sim = Helpers.jaccard_similarity(pair[0][list_type], pair[1][list_type])\n",
    "            if sim > self.THRESHOLD:\n",
    "                card1_id = pair[0]['id']\n",
    "                card2_id = pair[1]['id']\n",
    "                res.append((card1_id, card2_id, sim))\n",
    "                if card1_id not in represented:\n",
    "                    represented.append(card1_id)\n",
    "                if card2_id not in represented:\n",
    "                    represented.append(card2_id)\n",
    "\n",
    "        print(f'{n} cards total. {len(represented)} cards represented in matrix '\n",
    "              f'({100*len(represented)/n:.2f}%). '\n",
    "              f'At theshold {self.THRESHOLD}, storing {len(res)} of {perms} combos '\n",
    "              f'of {list_type} ({100*(1-len(res)/perms):.2f}% reduction)')\n",
    "        \n",
    "        tbl = list_type[:-1]\n",
    "        print(f'Serializing results into table note_{tbl}_sim')\n",
    "        self.serialize_note_similarity(tbl, res)\n",
    "        return res\n",
    "    \n",
    "    # idc if I'm repeating myself in these next two funcs\n",
    "    def tag_similarity(self):\n",
    "        all_tags = list(set(tag for taglist in [card['tags'] for card in self.db] for tag in taglist))\n",
    "        n_tags = len(all_tags)\n",
    "        \n",
    "        pairs = itertools.permutations(all_tags, 2)\n",
    "        perms = int(math.factorial(n_tags)/math.factorial(n_tags-2))\n",
    "        \n",
    "        res = []\n",
    "        represented = []\n",
    "        for pair in tqdm(pairs, f'Calculating similarity of tags: ',\n",
    "                         total = perms, position=0, leave=True):\n",
    "            tag1 = pair[0]\n",
    "            tag2 = pair[1]\n",
    "            tag1_cards = [card['id'] for card in self.db if tag1 in card['tags']]\n",
    "            tag2_cards = [card['id'] for card in self.db if tag2 in card['tags']]\n",
    "            sim = Helpers.jaccard_similarity(tag1_cards, tag2_cards)\n",
    "            \n",
    "            if sim != 0:\n",
    "                res.append((tag1, tag2, sim))\n",
    "                if tag1 not in represented:\n",
    "                    represented.append(tag1)\n",
    "                if tag2 not in represented:\n",
    "                    represented.append(tag2)\n",
    "                \n",
    "        print(f'{n_tags} total. {len(represented)} tags represented in matrix '\n",
    "              f'({100*len(represented)/n_tags:.2f}%). '\n",
    "              f'Storing {len(res)} nonzero values of {perms} tag combos '\n",
    "              f'({100*(1-len(res)/perms):.2f}% reduction).')\n",
    "        print('Serializing tag similarity')\n",
    "        self.sql.insert_multiple_vals(f'''\n",
    "                                  INSERT INTO tag_sim (tag_a, tag_b, value)\n",
    "                                  VALUES (?, ?, ?)\n",
    "                                   ''', res)\n",
    "        return res\n",
    "    \n",
    "    def image_similarity(self):\n",
    "        all_imgs = list(set(img for imglist in [card['images'] for card in self.db] for img in imglist))\n",
    "        n_imgs = len(all_imgs)\n",
    "        \n",
    "        pairs = itertools.permutations(all_imgs, 2)\n",
    "        perms = int(math.factorial(n_imgs)/math.factorial(n_imgs-2))\n",
    "        \n",
    "        res = []\n",
    "        represented = []\n",
    "        for pair in tqdm(pairs, f'Calculating similarity of images: ',\n",
    "                         total = perms, position=0, leave=True):\n",
    "            img1 = pair[0]\n",
    "            img2 = pair[1]\n",
    "            img1_cards = [card['id'] for card in self.db if img1 in card['images']]\n",
    "            img2_cards = [card['id'] for card in self.db if img2 in card['images']]\n",
    "            sim = Helpers.jaccard_similarity(img1_cards, img2_cards)\n",
    "            \n",
    "            if sim != 0:\n",
    "                res.append((img1, img2, sim))\n",
    "                if img1 not in represented:\n",
    "                    represented.append(img1)\n",
    "                if img2 not in represented:\n",
    "                    represented.append(img2)\n",
    "                \n",
    "        print(f'{n_imgs} total. {len(represented)} images represented in matrix '\n",
    "              f'({100*len(represented)/n_imgs:.2f}%). '\n",
    "              f'Storing {len(res)} nonzero values of {perms} image combos '\n",
    "              f'({100*(1-len(res)/perms):.2f}% reduction).')\n",
    "        print('Serializing image similarity')\n",
    "        self.sql.insert_multiple_vals(f'''\n",
    "                                  INSERT INTO image_sim (image_a, image_b, value)\n",
    "                                  VALUES (?, ?, ?)\n",
    "                                   ''', res)\n",
    "        return res\n",
    "            \n",
    "    def serialize_note_similarity(self, table, params):\n",
    "        self.sql.insert_multiple_vals(f'''\n",
    "                                  INSERT INTO note_{table}_sim (post_a, post_b, value)\n",
    "                                  VALUES (?, ?, ?)\n",
    "                                   ''', params)\n",
    "    \n",
    "    def load_from_db(self):\n",
    "        print(f'Loading from database {self.sql.path}')\n",
    "        self.note_sim['images'] = self.sql.execute_sql('SELECT * from note_image_sim;')\n",
    "        self.note_sim['tags'] = self.sql.execute_sql('SELECT * from note_tag_sim;')\n",
    "        self.note_sim['text'] = self.sql.execute_sql('SELECT * from note_text_sim;')\n",
    "        self.note_sim['overall'] = self.sql.execute_sql('SELECT * from note_overall_sim;')\n",
    "        self.tag_sim = self.sql.execute_sql('SELECT * from tag_sim;')\n",
    "        self.image_sim = self.sql.execute_sql('SELECT * from image_sim;')\n",
    "    \n",
    "    def set_threshold(self, threshold=0.15):\n",
    "        self.THRESHOLD = threshold\n",
    "    \n",
    "    \n",
    "class SQL(object):\n",
    "    DELAY = 0.5  # Just for display purposes\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "    \n",
    "    def init_sql(self):\n",
    "        print(f'Creating new storage db at {self.path}')\n",
    "        conn = sqlite3.connect(self.path)\n",
    "        cursor = conn.cursor()\n",
    "        for tbl in ['posts','tags','images',\n",
    "                    'note_image_sim', 'note_tag_sim', 'note_text_sim', 'note_overall_sim',\n",
    "                    'tag_sim', 'image_sim']:\n",
    "            cursor.execute(f'DROP TABLE IF EXISTS {tbl}')\n",
    "        \n",
    "        cursor.execute('CREATE TABLE posts (post_id integer);')\n",
    "        cursor.execute('CREATE TABLE tags (tag string);')\n",
    "        cursor.execute('CREATE TABLE images (image string);')\n",
    "        cursor.execute('CREATE INDEX posts_idx ON posts (post_id);')\n",
    "        cursor.execute('CREATE INDEX tags_idx ON tags (tag);')\n",
    "        cursor.execute('CREATE INDEX images_idx ON images (image);')\n",
    "        \n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_image_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (post_a) REFERENCES posts (post_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (post_b) REFERENCES posts (post_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_image_sim_idx ON note_image_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_tag_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (post_a) REFERENCES posts (post_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (post_b) REFERENCES posts (post_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_tag_sim_idx ON note_tag_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_text_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (post_a) REFERENCES posts (post_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (post_b) REFERENCES posts (post_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_text_sim_idx ON note_text_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE note_overall_sim\n",
    "                       (post_a integer, \n",
    "                       post_b integer,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (post_a) REFERENCES posts (post_id) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (post_b) REFERENCES posts (post_id) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX note_overall_sim_idx ON note_overall_sim (post_a, post_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE tag_sim\n",
    "                       (tag_a string, \n",
    "                       tag_b string,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (tag_a) REFERENCES tags (tag) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (tag_b) REFERENCES tags (tag) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX tag_sim_idx ON tag_sim (tag_a, tag_b);')\n",
    "        cursor.execute('''\n",
    "                       CREATE TABLE image_sim\n",
    "                       (image_a string, \n",
    "                       image_b string,\n",
    "                       value real,\n",
    "                       \n",
    "                       FOREIGN KEY (image_a) REFERENCES images (image) ON DELETE CASCADE,\n",
    "                       FOREIGN KEY (image_b) REFERENCES images (image) ON DELETE CASCADE);\n",
    "                       ''')\n",
    "        cursor.execute('CREATE INDEX image_sim_idx ON image_sim (image_a, image_b);')\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "    def execute_sql(self, sql, params=()):\n",
    "        with closing(sqlite3.connect(self.path)) as conn:\n",
    "            with conn:\n",
    "                cur = conn.cursor()\n",
    "                try:\n",
    "                    cur.execute(sql, params)\n",
    "                    res = cur.fetchall()\n",
    "                except sqlite3.ProgrammingError:\n",
    "                    print(f'SQL:\\n{sql}\\n{params}')\n",
    "\n",
    "                if res:\n",
    "                    df = pd.DataFrame(res)\n",
    "                    df.columns = [d[0] for d in cur.description]\n",
    "                else:\n",
    "                    df = pd.DataFrame({})\n",
    "        return df\n",
    "    \n",
    "    def insert_multiple_vals(self, sql, param_list):\n",
    "        with closing(sqlite3.connect(self.path)) as conn:\n",
    "            with conn:\n",
    "                cur = conn.cursor()\n",
    "                try:\n",
    "                    sleep(self.DELAY)\n",
    "                    for params in tqdm(param_list, 'Serializing', position=0, leave=True):\n",
    "                        cur.execute(sql, params)\n",
    "                    res = cur.fetchall()\n",
    "                except sqlite3.ProgrammingError:\n",
    "                    print(f'SQL:\\n{sql}\\n{params}')\n",
    "\n",
    "                if res:\n",
    "                    df = pd.DataFrame(res)\n",
    "                    df.columns = [d[0] for d in cur.description]\n",
    "                else:\n",
    "                    df = pd.DataFrame({})\n",
    "        return df\n",
    "        \n",
    "\n",
    "class Helpers(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_html_tags(markup):\n",
    "        soup = BeautifulSoup(markup, 'html.parser')\n",
    "        for br in soup.find_all('br'):\n",
    "            br.replace_with('\\n')\n",
    "        return soup.get_text()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_images(markup):\n",
    "        out = []\n",
    "        if markup:\n",
    "            soup = BeautifulSoup(markup, 'html.parser')\n",
    "            images = soup.findAll('img')\n",
    "            for image in images:\n",
    "                out.append(image['src'])  \n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_cloze(markup):\n",
    "        # txt = '<a href=\"blah\"> Hello {{c1::world}} once {{c2::again::hint}} lol </a>'\n",
    "        return re.sub('{{.*?::(.*?)(::.*?){0,}}}', '\\\\1', markup)\n",
    "    \n",
    "    @staticmethod\n",
    "    def telescope_tags(taglist):\n",
    "        out = []\n",
    "        for tag in taglist:\n",
    "            splt = tag.lower().split('::')\n",
    "            for i in range(1, len(splt)):\n",
    "                out.append('::'.join(splt[0:i]))\n",
    "        return set(out)\n",
    "\n",
    "    @staticmethod\n",
    "    def jaccard_similarity(list1, list2):\n",
    "        s1 = set(list1)\n",
    "        s2 = set(list2)\n",
    "        try:\n",
    "            jaccard = float(len(s1.intersection(s2)) / len(s1.union(s2)))\n",
    "        except ZeroDivisionError:\n",
    "            jaccard = 0\n",
    "        return jaccard\n",
    "\n",
    "# TODO: Calculate similarity based on text\n",
    "# TODO: Calculate network fusion\n",
    "\n",
    "# TODO: combine all the whitespace? Handle punctuation?\n",
    "# TODO: similarity of tags/images rather than notes \n",
    "# (easier to compute: simply count how many notes any 2 tags have in common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:32:23.877512Z",
     "start_time": "2022-06-23T18:32:10.266084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new storage db at /mnt/c/Users/edrid.EDRIDGE-DSOUZA-/Documents/GitHub/anki-network/Subset.apkg.sql\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading `/mnt/c/Users/edrid.EDRIDGE-DSOUZA-/Documents/GitHub/anki-network/Subset.apkg`: 100%|██████████| 572/572 [00:00<00:00, 683.66it/s]\n"
     ]
    }
   ],
   "source": [
    "file = 'Subset.apkg' # Selected Notes.apkg or Subset.apkg\n",
    "\n",
    "x = Anki(file)\n",
    "x.set_threshold(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:24:50.029561Z",
     "start_time": "2022-06-23T18:24:48.820339Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarity of cards by their images: 100%|██████████| 284622/284622 [00:00<00:00, 448729.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534 cards total. 227 cards represented in matrix (42.51%). At theshold 0.15, storing 2098 of 284622 combos of images (99.26% reduction)\n",
      "Serializing results into table note_image_sim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 2098/2098 [00:00<00:00, 76924.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "x.note_image_similarity()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:25:15.060797Z",
     "start_time": "2022-06-23T18:25:12.071566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarity of cards by their tags: 100%|██████████| 284622/284622 [00:01<00:00, 185322.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534 cards total. 358 cards represented in matrix (67.04%). At theshold 0.15, storing 136468 of 284622 combos of tags (52.05% reduction)\n",
      "Serializing results into table note_tag_sim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 136468/136468 [00:00<00:00, 161576.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "x.note_tag_similarity()\n",
    "# x.note_text_similarity()\n",
    "# x.note_overall_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:32:38.359297Z",
     "start_time": "2022-06-23T18:32:27.806475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating similarity of tags: 100%|██████████| 193160/193160 [00:09<00:00, 19848.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 total. 440 tags represented in matrix (100.00%). Storing 19518 nonzero values of 193160 tag combos (89.90% reduction).\n",
      "Serializing tag similarity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serializing: 100%|██████████| 19518/19518 [00:00<00:00, 86274.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "x.tag_similarity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%prun\n",
    "x.image_similarity()\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:11:18.855862Z",
     "start_time": "2022-06-23T16:33:50.068Z"
    }
   },
   "outputs": [],
   "source": [
    "x.db[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:11:18.857216Z",
     "start_time": "2022-06-23T16:33:50.069Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "x = Anki(file, overwrite=False, read=False)\n",
    "x.load_from_db()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:11:18.858339Z",
     "start_time": "2022-06-23T16:33:50.070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Doc2Vec for similarity scores:\n",
    "# https://medium.com/red-buffer/doc2vec-computing-similarity-between-the-documents-47daf6c828cd\n",
    "# https://stackoverflow.com/questions/53503049/measure-similarity-between-two-documents-using-doc2vec\n",
    "# https://github.com/jhlau/doc2vec#pre-trained-doc2vec-models\n",
    "\n",
    "# https://github.com/rmarkello/snfpy to fuse similarity networks\n",
    "# https://github.com/maxconway/SNFtool has more visualization options\n",
    "# sklearn to do general network stuff\n",
    "# https://towardsdatascience.com/visualising-similarity-clusters-with-interactive-graphs-20a4b2a18534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-23T18:11:18.859524Z",
     "start_time": "2022-06-23T16:33:50.071Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "from scipy import spatial\n",
    "\n",
    "d2v_model = doc2vec.Doc2Vec.load(model_file)\n",
    "\n",
    "fisrt_text = '..'\n",
    "second_text = '..'\n",
    "\n",
    "vec1 = d2v_model.infer_vector(fisrt_text.split())\n",
    "vec2 = d2v_model.infer_vector(second_text.split())\n",
    "\n",
    "cos_distance = spatial.distance.cosine(vec1, vec2)\n",
    "# cos_distance indicates how much the two texts differ from each other:\n",
    "# higher values mean more distant (i.e. different) texts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
